# TARS 実装ロードマップ（48時間）

## 📋 現在の状態

✅ **完了済み**
- [x] プロジェクト構造作成
- [x] FastAPIバックエンド実装（Vertex AI Gemini統合）
- [x] Matter.jsフロントエンド実装
- [x] Docker/Cloud Run設定ファイル
- [x] デプロイスクリプト
- [x] README & セットアップガイド

## 🎯 今後48時間の優先タスク

### 【最優先】Day 1 - 前半4時間

#### 1. GCPセットアップ & 初回デプロイ（2時間）⚠️ **CRITICAL**

```bash
# 1. プロジェクト作成・設定
gcloud projects create tars-robot-safety-2026 --name="TARS Robot Safety"
gcloud config set project tars-robot-safety-2026

# 2. 課金アカウント設定（GCPコンソールで）
# https://console.cloud.google.com/billing

# 3. API有効化
gcloud services enable aiplatform.googleapis.com
gcloud services enable run.googleapis.com
gcloud services enable cloudbuild.googleapis.com

# 4. 初回デプロイ
./deploy.sh
```

**成功基準:**
- Cloud RunのURLが発行される
- ブラウザでアクセスしてMatter.jsシミュレーションが表示される
- `/health` エンドポイントが "connected" を返す

#### 2. プロンプトエンジニアリング初期テスト（2時間）⚠️ **HIGH RISK**

**目的:** Gemini Visionが座標を正確に返せるかテスト

**テスト手順:**
1. シミュレーションを開始
2. AI分析ボタンをクリック
3. レスポンスをブラウザコンソールで確認
4. 座標の精度を評価（目標: 80%以上正確）

**プロンプト改善案:**
```python
# backend/main.py の SYSTEM_PROMPT を修正

SYSTEM_PROMPT_V2 = """あなたは工場安全分析AIです。

画像は900x600ピクセルの2D工場フロアです。
- 青い円 = 作業員
- 赤い/オレンジの四角 = ロボット
- 灰色 = 障害物

以下の厳密なJSON形式で応答してください（他のテキストは含めない）:

{
  "entities": [
    {
      "type": "worker",
      "bbox": [0.16, 0.49, 0.19, 0.52],
      "risk_level": 75,
      "movement": "moving_slow"
    }
  ],
  "warnings": ["作業員がロボットに接近"],
  "interventions": [
    {
      "type": "barrier",
      "position": [0.5, 0.5],
      "reason": "衝突防止"
    }
  ],
  "confidence": 0.85
}

座標は画像サイズで正規化（0.0〜1.0）してください。"""
```

**フォールバックプラン:**
- 座標抽出が80%未満の精度なら → 簡易版（危険度のみ、座標は手動）に切り替え

---

### Day 1 - 後半4時間

#### 3. 複数シナリオの実装（3時間）

**目標:** 3つの異なる危険シナリオを作成

**シナリオ1: 衝突回避**
- 作業員がロボットの動作範囲に接近
- AIが中間に安全バリアを配置

**シナリオ2: 挟まれ防止**
- 作業員が壁とロボットの間に
- AIがロボット減速を指示

**シナリオ3: 危険エリア警告**
- 床に危険エリア（赤い領域）を追加
- 作業員が近づくと警告

**実装方法:**
```javascript
// frontend/js/app.js に追加

function loadScenario(scenarioId) {
    resetSimulation();
    
    if (scenarioId === 1) {
        // シナリオ1: 衝突回避
        Body.setPosition(worker, { x: 300, y: 300 });
        Body.setPosition(robot, { x: 600, y: 300 });
        Body.setVelocity(worker, { x: 2, y: 0 });
        Body.setVelocity(robot, { x: -2, y: 0 });
    }
    // ... 他のシナリオ
}
```

**UI追加:**
- シナリオ選択ドロップダウン
- シナリオ説明パネル

#### 4. UI/UXポリッシュ（1時間）

- 危険度ヒートマップ追加
- AI判断の可視化（思考プロセス表示）
- アニメーション改善
- カラースキーム統一

---

### Day 2 - 前半4時間

#### 5. プロンプト最適化（3時間）⚠️ **CRITICAL**

**目標:** Geminiの座標抽出精度を90%以上に

**アプローチ:**
1. **Few-shot Learning:** プロンプトに例を追加
2. **JSON Mode:** Gemini 2.0のJSON出力モード使用
3. **Function Calling:** 構造化出力の活用
4. **エラーハンドリング:** パース失敗時のリトライロジック

**テストセット作成:**
```bash
# 10パターンのスクリーンショットを手動で保存
frontend/test_images/
  - scenario1_collision.png
  - scenario2_trapped.png
  - scenario3_hazard.png
  ...
```

**自動テスト:**
```python
# backend/test_prompts.py
import asyncio
from pathlib import Path

async def test_all_scenarios():
    for img_path in Path("../frontend/test_images").glob("*.png"):
        # Gemini呼び出し
        # 結果を評価
        pass
```

#### 6. デモ動画撮影準備（1時間）

- 3シナリオのスクリプト作成
- 画面録画ツール設定（OBSなど）
- ナレーション原稿準備

---

### Day 2 - 後半4時間

#### 7. デモ動画撮影 & 編集（2時間）

**構成（3分）:**
- 0:00-0:20: 課題提示（協働ロボットの安全性問題）
- 0:20-0:40: ソリューション紹介（TARS概要）
- 0:40-1:30: シナリオ1実演
- 1:30-2:20: シナリオ2-3実演
- 2:20-3:00: 効果とまとめ

**撮影チェックリスト:**
- [ ] 画面が鮮明（1080p以上）
- [ ] 音声が明瞭（ノイズなし）
- [ ] 各シナリオでAIが正しく動作
- [ ] カウンターが増加する様子を見せる
- [ ] UIが美しく見える

#### 8. Zenn記事執筆（2時間）

**記事構成:**
```markdown
# TARS - AI空間知能で実現する協働ロボット安全システム

## 課題
- 協働ロボット市場の急成長
- 労災リスクが導入の障壁
- 既存の事後対応型システムの限界

## ソリューション
- Gemini Visionによる予測的安全
- Matter.jsでの物理シミュレーション
- クラウドネイティブな実装

## アーキテクチャ
[図を挿入]

## デモ
[YouTube動画埋め込み]

## 技術的詳細
- Vertex AI統合
- プロンプトエンジニアリング
- Cloud Runデプロイ

## 効果と今後
- 事故を未然に防ぐ
- 中小企業でも導入可能
- スケーラブルな設計
```

**設定:**
- カテゴリ: Idea
- トピック: `gch4`

---

### Day 2+ - 予備時間（8時間）

#### 9. 最終調整 & バグ修正（4時間）

- [ ] 全シナリオで10回ずつテスト
- [ ] エッジケースの処理
- [ ] エラーメッセージの改善
- [ ] パフォーマンス最適化
- [ ] モバイル対応（時間があれば）

#### 10. ハッカソン提出準備（2時間）

- [ ] GitHubリポジトリ公開確認
- [ ] README完成度チェック
- [ ] デプロイURL動作確認
- [ ] Zenn記事公開
- [ ] 提出フォーム記入

#### 11. プレゼン練習（2時間）

- [ ] デモを10回実行
- [ ] 想定質問への回答準備
- [ ] インターネット障害時の対応確認
- [ ] 録画デモのバックアップ

---

## 🚨 リスク管理

### Risk #1: Geminiの座標抽出失敗
**確率:** 高（50%）
**影響:** 大
**対策:**
- フォールバックプラン: 記述的警告のみ（座標なし）
- モックデータでデモ

### Risk #2: Cloud Runのコールドスタート
**確率:** 中（30%）
**影響:** 中
**対策:**
- min-instances=1に設定（デモ前のみ）
- 事前にウォームアップリクエスト

### Risk #3: デモ当日のインターネット障害
**確率:** 低（10%）
**影響:** 大
**対策:**
- 録画デモ準備
- ローカル環境でも動作するよう設定

### Risk #4: Gemini APIレート制限
**確率:** 中（20%）
**影響:** 中
**対策:**
- デモ用のキャッシュ機能
- リトライロジック実装

---

## ✅ 完了チェックリスト

### 必須（審査に影響）
- [ ] Cloud Runデプロイ成功
- [ ] Gemini Vision動作確認
- [ ] 3シナリオ実装
- [ ] デモ動画作成（3分）
- [ ] Zenn記事公開
- [ ] GitHubリポジトリ公開

### 推奨（評価向上）
- [ ] プロンプト最適化完了（精度90%+）
- [ ] UI/UX美しい
- [ ] README詳細
- [ ] アーキテクチャ図作成
- [ ] エラーハンドリング完璧

### 理想（時間があれば）
- [ ] モバイル対応
- [ ] 統計ダッシュボード
- [ ] WebSocket対応
- [ ] 複数カメラ視点

---

## 📊 時間配分の最適化

| タスク | 時間 | 優先度 |
|--------|------|--------|
| GCPセットアップ & デプロイ | 2h | ⚠️ CRITICAL |
| プロンプトエンジニアリング | 5h | ⚠️ CRITICAL |
| 複数シナリオ実装 | 3h | 🔴 HIGH |
| UI/UXポリッシュ | 2h | 🟠 MEDIUM |
| デモ動画 | 2h | 🔴 HIGH |
| Zenn記事 | 2h | 🔴 HIGH |
| テスト & デバッグ | 4h | 🟠 MEDIUM |
| 予備時間 | 4h | - |
| **合計** | **24h** | |

---

## 🎯 成功の定義

**最低限（提出可能レベル）:**
- Cloud Runで動作
- 1シナリオがデモ可能
- 動画とZenn記事提出

**目標（入賞狙い）:**
- 3シナリオがスムーズに動作
- Gemini精度90%以上
- UIが美しく直感的
- デモ動画がプロフェッショナル

**理想（最優秀賞）:**
- すべての機能が完璧
- 技術的な新規性が明確
- 社会的インパクトが大きい
- プレゼンが説得力ある

---

## 📞 緊急時の連絡先

- Discord: ハッカソンチャンネル
- GitHub Issues: 技術的な質問
- Google Cloud サポート: インフラ問題

---

**次のアクション:**
```bash
./deploy.sh
```

まずはデプロイから始めましょう！🚀
