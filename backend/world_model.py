"""
TARS - World Model: LLM-driven Physics Reasoning

Gemini APIã‚’ä½¿ã£ãŸç©ºé–“çŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ 
ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¦³å¯Ÿã—ã€æ¬¡ã®è¡Œå‹•ã‚’æ¨è«–ã™ã‚‹
"""

import json
from datetime import datetime

from pydantic import BaseModel, Field
from task import Action, LevelConfig


class EpisodeMemory(BaseModel):
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ï¼ˆGenerative Agentsé¢¨ï¼‰"""

    episode_id: int = Field(description="ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ID")
    level_key: str = Field(description="ãƒ¬ãƒ™ãƒ«è­˜åˆ¥å­")
    level_name: str = Field(description="ãƒ¬ãƒ™ãƒ«å")
    timestamp: str = Field(description="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—")
    success: bool = Field(description="æˆåŠŸ/å¤±æ•—")
    steps: int = Field(description="ä½¿ç”¨ã‚¹ãƒ†ãƒƒãƒ—æ•°")
    elapsed_time: float = Field(description="çµŒéæ™‚é–“ï¼ˆç§’ï¼‰")
    reward: float = Field(description="ç²å¾—å ±é…¬")
    actions_taken: list[str] = Field(description="å®Ÿè¡Œã—ãŸè¡Œå‹•ãƒªã‚¹ãƒˆ")
    final_distance: float = Field(description="æœ€çµ‚çš„ãªã‚´ãƒ¼ãƒ«ã¾ã§ã®è·é›¢")
    summary: str = Field(description="ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®ã‚µãƒãƒªãƒ¼")
    key_insight: str | None = Field(
        default=None, description="ã“ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸé‡è¦ãªæ´å¯Ÿ"
    )


class Reflection(BaseModel):
    """ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆè¤‡æ•°ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã®å­¦ç¿’ï¼‰"""

    level_key: str = Field(description="ãƒ¬ãƒ™ãƒ«è­˜åˆ¥å­")
    pattern: str = Field(description="ç™ºè¦‹ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³")
    successful_strategy: str | None = Field(default=None, description="æˆåŠŸã—ãŸæˆ¦ç•¥")
    failed_attempts: list[str] = Field(default_factory=list, description="å¤±æ•—ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ")
    improvement_hint: str = Field(description="æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ")


class MemoryStream:
    """è¨˜æ†¶ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆGenerative Agentsã®ãƒ¡ãƒ¢ãƒªã‚·ã‚¹ãƒ†ãƒ ï¼‰"""

    def __init__(self):
        self.episodes: list[EpisodeMemory] = []
        self.reflections: dict[str, Reflection] = {}  # level_key -> Reflection
        self.episode_counter = 0

    def add_episode(
        self,
        level_key: str,
        level_name: str,
        success: bool,
        steps: int,
        elapsed_time: float,
        reward: float,
        actions_taken: list[str],
        final_distance: float,
    ) -> EpisodeMemory:
        """æ–°ã—ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’è¨˜æ†¶ã«è¿½åŠ """

        self.episode_counter += 1

        summary = create_episode_summary(
            level_name=level_name,
            success=success,
            steps=steps,
            reward=reward,
            actions_taken=actions_taken,
        )

        # é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡º
        key_insight = None
        if success:
            if steps < 10:
                key_insight = "æœ€çŸ­ãƒ«ãƒ¼ãƒˆã‚’ç™ºè¦‹ï¼åŠ¹ç‡çš„ãªãƒ€ pushæˆ¦ç•¥ãŒæœ‰åŠ¹"
            elif "barrier" in actions_taken:
                key_insight = "ãƒãƒªã‚¢ã‚’æ´»ç”¨ã—ãŸèª˜å°è·¯ãŒæˆåŠŸ"
        else:
            if "ç”»é¢å¤–" in summary:
                key_insight = "åŠ›ãŒå¼·ã™ãã¦åˆ¶å¾¡ä¸èƒ½ã«â†’æ¬¡å›ã¯ã‚ˆã‚Šæ…é‡ã«"
            elif "æ™‚é–“åˆ‡ã‚Œ" in summary:
                key_insight = "å‹•ä½œãŒé…ã™ãã‚‹â†’ã‚ˆã‚Šå¼·ã„åŠ›ãŒå¿…è¦"

        episode = EpisodeMemory(
            episode_id=self.episode_counter,
            level_key=level_key,
            level_name=level_name,
            timestamp=datetime.now().isoformat(),
            success=success,
            steps=steps,
            elapsed_time=elapsed_time,
            reward=reward,
            actions_taken=actions_taken,
            final_distance=final_distance,
            summary=summary,
            key_insight=key_insight,
        )

        self.episodes.append(episode)

        # ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°
        self._update_reflection(level_key)

        return episode

    def _update_reflection(self, level_key: str):
        """ã“ã®ãƒ¬ãƒ™ãƒ«ã«é–¢ã™ã‚‹ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ›´æ–°"""

        level_episodes = [e for e in self.episodes if e.level_key == level_key]

        if not level_episodes:
            return

        successes = [e for e in level_episodes if e.success]
        failures = [e for e in level_episodes if not e.success]

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç™ºè¦‹
        pattern = f"{len(successes)}/{len(level_episodes)}å›æˆåŠŸ"

        # æˆåŠŸæˆ¦ç•¥
        successful_strategy = None
        if successes:
            # æœ€ã‚‚åŠ¹ç‡çš„ãªæˆåŠŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ç‰¹å®š
            best = min(successes, key=lambda e: e.steps)
            successful_strategy = (
                f"ã‚¹ãƒ†ãƒƒãƒ—{best.steps}ã§ã‚¯ãƒªã‚¢: {', '.join(best.actions_taken[:5])}"
            )

        # å¤±æ•—ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
        failed_attempts = []
        for failure in failures[-3:]:  # æœ€è¿‘ã®3å›ã®å¤±æ•—
            if failure.key_insight:
                failed_attempts.append(failure.key_insight)

        # æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
        improvement_hint = "ã¾ã è©¦è¡ŒéŒ¯èª¤ä¸­ã§ã™"
        if len(level_episodes) >= 3:
            if successes:
                improvement_hint = f"æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºç«‹: {successful_strategy}"
            else:
                improvement_hint = "ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è©¦ã—ã¦ãã ã•ã„"

        self.reflections[level_key] = Reflection(
            level_key=level_key,
            pattern=pattern,
            successful_strategy=successful_strategy,
            failed_attempts=failed_attempts,
            improvement_hint=improvement_hint,
        )

    def get_reflection(self, level_key: str) -> Reflection | None:
        """ç‰¹å®šãƒ¬ãƒ™ãƒ«ã®ãƒªãƒ•ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
        return self.reflections.get(level_key)

    def get_recent_episodes(self, level_key: str, limit: int = 5) -> list[EpisodeMemory]:
        """æœ€è¿‘ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å–å¾—"""
        level_episodes = [e for e in self.episodes if e.level_key == level_key]
        return level_episodes[-limit:]

    def get_stats(self) -> dict:
        """çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        if not self.episodes:
            return {"total_episodes": 0}

        success_count = sum(1 for e in self.episodes if e.success)
        total_reward = sum(e.reward for e in self.episodes)

        return {
            "total_episodes": len(self.episodes),
            "success_rate": success_count / len(self.episodes) if self.episodes else 0,
            "total_reward": total_reward,
            "average_reward": total_reward / len(self.episodes) if self.episodes else 0,
        }


class WorldModelPrompt:
    """World Modelç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""

    SYSTEM_PROMPT = """ã‚ãªãŸã¯ç‰©ç†æ³•å‰‡ã‚’ç†è§£ã™ã‚‹ç©ºé–“çŸ¥èƒ½AIã§ã™ã€‚

**ã‚¿ã‚¹ã‚¯**: å€‰åº«å†…ã§è·ç‰©ï¼ˆé’ã„ç®±ï¼‰ã‚’ã‚´ãƒ¼ãƒ«ï¼ˆé‡‘è‰²ã®å††ï¼‰ã¾ã§ç§»å‹•ã•ã›ã‚‹

**ç‰©ç†æ³•å‰‡**:
- é‡åŠ›: ä¸‹æ–¹å‘ã«å¸¸ã«åƒã (gravity.y = 1.0)
- æ‘©æ“¦: è¡¨é¢ã¨ã®æ‘©æ“¦ã§æ¸›é€Ÿ (ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã‚Šç•°ãªã‚‹)
- åç™º: å£ã‚„éšœå®³ç‰©ã¨ã®è¡çªã§è·³ã­è¿”ã‚‹ (restitution = 0.3)
- è³ªé‡: è·ç‰©ã®è³ªé‡ãŒå¤§ãã„ã»ã©å‹•ãã«ãã„ (mass = 10kg)

**åˆ©ç”¨å¯èƒ½ãªè¡Œå‹•**:
1. **push**: è·ç‰©ã«åŠ›ã‚’åŠ ãˆã‚‹
   - forceX, forceY: åŠ›ã®æ–¹å‘ã¨å¤§ãã• (æ¨å¥¨ç¯„å›²: 50ã€œ150)
   - duration: åŠ›ã‚’åŠ ãˆã‚‹æ™‚é–“ï¼ˆãƒŸãƒªç§’ã€100-500æ¨å¥¨ï¼‰
   - å‚è€ƒå€¤: 50-80ç¨‹åº¦ã®åŠ›ã§è·ç‰©ã‚’å‹•ã‹ã—ã€100ä»¥ä¸Šã§ã‚ˆã‚Šé€Ÿãç§»å‹•
   - æ³¨æ„: ç©ºæ°—æŠµæŠ—ã«ã‚ˆã‚Šé€Ÿåº¦ã¯è‡ªç„¶ã«æ¸›è¡°ã—ã¾ã™ã€‚è¤‡æ•°å›æŠ¼ã™ã“ã¨ã§åŠ é€Ÿã§ãã¾ã™

2. **barrier**: ãƒãƒªã‚¢ï¼ˆæ–œé¢ï¼‰ã‚’é…ç½®ã—ã¦è·ç‰©ã‚’èª˜å°
   - x, y: é…ç½®ä½ç½®
   - angle: è§’åº¦ï¼ˆåº¦ã€0=æ°´å¹³ã€90=å‚ç›´ï¼‰
   - ãƒ¬ãƒ™ãƒ«ã«ã‚ˆã£ã¦ä½¿ç”¨å›æ•°åˆ¶é™ã‚ã‚Š

3. **wait**: ä½•ã‚‚ã›ãšè¦³å¯Ÿï¼ˆè·ç‰©ãŒå‹•ã„ã¦ã„ã‚‹æ™‚ã«æœ‰åŠ¹ï¼‰
   - duration: å¾…æ©Ÿæ™‚é–“ï¼ˆãƒŸãƒªç§’ã€500-2000æ¨å¥¨ï¼‰

4. **observe**: çŠ¶æ³ã‚’è©³ã—ãè¦³å¯Ÿï¼ˆæ¬¡ã®æˆ¦ç•¥ã‚’è€ƒãˆã‚‹ï¼‰
   - focus: æ³¨ç›®ã™ã‚‹è¦ç´ ï¼ˆä¾‹: "velocity", "obstacles"ï¼‰

**è©•ä¾¡åŸºæº–**:
- ã‚´ãƒ¼ãƒ«åˆ°é”: +100ç‚¹
- åŠ¹ç‡æ€§: å°‘ãªã„ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚¯ãƒªã‚¢ï¼ˆãƒœãƒ¼ãƒŠã‚¹æœ€å¤§+50ï¼‰
- ã‚¹ãƒ ãƒ¼ã‚ºãªå‹•ã: æ€¥æ¿€ãªåŠ›ã‚’é¿ã‘ã‚‹ (+20ç‚¹)
- æ–°è¦æˆ¦ç•¥: æœªçŸ¥ã®è§£æ³•ã‚’ç™ºè¦‹ (+30ç‚¹)
- å¤±æ•—ãƒšãƒŠãƒ«ãƒ†ã‚£: ç”»é¢å¤–ã«è½ä¸‹ (-50ç‚¹)ã€æ™‚é–“åˆ‡ã‚Œ (-30ç‚¹)

**é‡è¦ãªè€ƒæ…®äº‹é …**:
- æ‘©æ“¦ãŒä½ã„ãƒ¬ãƒ™ãƒ«ã§ã¯ã€è·ç‰©ãŒæ»‘ã‚Šã‚„ã™ã„ã®ã§å¾®èª¿æ•´ãŒå¿…è¦
- å£ãŒã‚ã‚‹å ´åˆã¯ã€è¿‚å›è·¯ã‚’è€ƒãˆã‚‹
- ãƒãƒªã‚¢ã‚’ä½¿ãˆã‚‹å ´åˆã¯ã€æ»‘ã‚Šå°ã‚„èª˜å°è·¯ã‚’ä½œã‚‹ã¨åŠ¹ç‡çš„
- éå‰°ãªåŠ›ã¯é€†åŠ¹æœï¼ˆè·³ã­è¿”ã‚Šã‚„åˆ¶å¾¡ä¸èƒ½ï¼‰

ã‚ãªãŸã®ç›®æ¨™ã¯ã€ç‰©ç†æ³•å‰‡ã‚’ç†è§£ã—ã€æœ€ã‚‚åŠ¹ç‡çš„ãªæ–¹æ³•ã§ã‚´ãƒ¼ãƒ«ã‚’é”æˆã™ã‚‹ã“ã¨ã§ã™ã€‚"""

    @staticmethod
    def create_observation_prompt(
        level: LevelConfig,
        state: dict,
        step: int,
        previous_actions: list[str],
        reflection: Reflection | None = None,
        recent_episodes: list[EpisodeMemory] = None,
    ) -> str:
        """è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¨è«–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""

        box_pos = state["box"]["position"]
        box_vel = state["box"]["velocity"]
        goal_pos = state["goal"]["position"]
        goal_radius = state["goal"]["radius"]

        # è·é›¢ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
        dx = goal_pos["x"] - box_pos["x"]
        dy = goal_pos["y"] - box_pos["y"]
        distance = (dx**2 + dy**2) ** 0.5

        # é€Ÿåº¦ã®å¤§ãã•
        speed = (box_vel["x"] ** 2 + box_vel["y"] ** 2) ** 0.5

        prompt = f"""**ç¾åœ¨ã®çŠ¶æ³**:

**ãƒ¬ãƒ™ãƒ«**: {level.name}
- èª¬æ˜: {level.description}
- æ™‚é–“åˆ¶é™: {level.time_limit}ç§’
- æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—: {level.max_steps}
- åˆ©ç”¨å¯èƒ½ãƒãƒªã‚¢: {level.available_barriers}å€‹

**è·ç‰©ã®çŠ¶æ…‹**:
- ä½ç½®: ({box_pos["x"]:.1f}, {box_pos["y"]:.1f})
- é€Ÿåº¦: ({box_vel["x"]:.2f}, {box_vel["y"]:.2f}) - é€Ÿã•: {speed:.2f} px/s
- è³ªé‡: {level.box_mass}kg
- æ‘©æ“¦ä¿‚æ•°: {level.friction}

**ã‚´ãƒ¼ãƒ«ã®çŠ¶æ…‹**:
- ä½ç½®: ({goal_pos["x"]:.1f}, {goal_pos["y"]:.1f})
- åŠå¾„: {goal_radius}px
- è·é›¢: {distance:.1f}px
- æ–¹å‘: {"å³" if dx > 0 else "å·¦"} {abs(dx):.1f}px, {"ä¸‹" if dy > 0 else "ä¸Š"} {abs(dy):.1f}px

**é€²æ—**:
- ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—: {step}/{level.max_steps}
- çµŒéæ™‚é–“: {state["elapsedTime"]:.1f}/{level.time_limit}ç§’
"""

        if level.obstacles:
            prompt += f"\n**éšœå®³ç‰©**: {len(level.obstacles)}å€‹å­˜åœ¨\n"
            for _i, obs in enumerate(level.obstacles):
                prompt += f"  - {obs['type']}: ({obs['x']}, {obs['y']}) ã‚µã‚¤ã‚º{obs['width']}x{obs['height']}\n"

        if previous_actions:
            recent = previous_actions[-3:] if len(previous_actions) > 3 else previous_actions
            prompt += f"\n**ç›´å‰ã®è¡Œå‹•**: {', '.join(recent)}\n"

        # è¨˜æ†¶ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰ã®æƒ…å ±ã‚’è¿½åŠ ï¼ˆGenerative Agentsé¢¨ï¼‰
        if reflection:
            prompt += "\n**ğŸ“š è¨˜æ†¶ã‹ã‚‰ã®æ´å¯Ÿ** (ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å±¥æ­´):\n"
            prompt += f"- ãƒ‘ã‚¿ãƒ¼ãƒ³: {reflection.pattern}\n"
            if reflection.successful_strategy:
                prompt += f"- âœ… æˆåŠŸæˆ¦ç•¥: {reflection.successful_strategy}\n"
            if reflection.failed_attempts:
                prompt += "- âŒ å¤±æ•—ã‹ã‚‰å­¦ã¶:\n"
                for attempt in reflection.failed_attempts[-2:]:
                    prompt += f"  â€¢ {attempt}\n"
            prompt += f"- ğŸ’¡ æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ: {reflection.improvement_hint}\n"

        if recent_episodes:
            prompt += "\n**ğŸ§  æœ€è¿‘ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰** (æœ€å¤§3å›):\n"
            for ep in recent_episodes[-3:]:
                result_emoji = "âœ…" if ep.success else "âŒ"
                prompt += f"- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰{ep.episode_id} {result_emoji}: ã‚¹ãƒ†ãƒƒãƒ—{ep.steps}, å ±é…¬{ep.reward:.0f}\n"
                if ep.key_insight:
                    prompt += f"  æ´å¯Ÿ: {ep.key_insight}\n"

        prompt += """
**è³ªå•**: ä¸Šè¨˜ã®ç‰©ç†çŠ¶æ³ã‚’åˆ†æã—ã€æ¬¡ã«å–ã‚‹ã¹ãæœ€é©ãªè¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

**å›ç­”å½¢å¼** (å¿…ãšJSONå½¢å¼ã§):
```json
{{
  "reasoning": "ç‰©ç†çš„æ¨è«–ã¨æˆ¦ç•¥ã®èª¬æ˜ï¼ˆæ—¥æœ¬èªã€2-3æ–‡ï¼‰",
  "action": {{
    "type": "push" | "barrier" | "wait" | "observe",
    "forceX": æ•°å€¤ï¼ˆpushã®å ´åˆã€ä¾‹: 30.0ï¼‰,
    "forceY": æ•°å€¤ï¼ˆpushã®å ´åˆã€ä¾‹: 10.0ï¼‰,
    "duration": æ•°å€¤ï¼ˆpush/waitã®å ´åˆã€ãƒŸãƒªç§’å˜ä½ã€ä¾‹: 500ï¼‰,
    "x": æ•°å€¤ï¼ˆbarrierã®å ´åˆï¼‰,
    "y": æ•°å€¤ï¼ˆbarrierã®å ´åˆï¼‰,
    "angle": æ•°å€¤ï¼ˆbarrierã®å ´åˆã€åº¦ã€ä¾‹: 45ï¼‰,
    "focus": "æ–‡å­—åˆ—ï¼ˆobserveã®å ´åˆï¼‰",
    "reason": "è¡Œå‹•ã®ç°¡æ½”ãªç†ç”±ï¼ˆæ—¥æœ¬èªã€1æ–‡ï¼‰"
  }}
}}
```

ç‰©ç†æ³•å‰‡ã‚’è€ƒæ…®ã—ã€æœ€ã‚‚åŠ¹ç‡çš„ãªè¡Œå‹•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"""

        return prompt


class WorldModelResponse(BaseModel):
    """World Modelã‹ã‚‰ã®å¿œç­”"""

    reasoning: str = Field(description="ç‰©ç†çš„æ¨è«–ã¨æˆ¦ç•¥")
    action: Action = Field(description="é¸æŠã•ã‚ŒãŸè¡Œå‹•")
    raw_response: str = Field(description="Geminiã®ç”Ÿã®å¿œç­”")


async def analyze_and_decide(
    level: LevelConfig,
    level_key: str,
    state: dict,
    step: int,
    previous_actions: list[str],
    gemini_model,
    memory_stream: MemoryStream | None = None,
) -> WorldModelResponse:
    """
    ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’åˆ†æã—ã€æ¬¡ã®è¡Œå‹•ã‚’æ±ºå®š

    Args:
        level: ãƒ¬ãƒ™ãƒ«è¨­å®š
        level_key: ãƒ¬ãƒ™ãƒ«è­˜åˆ¥å­ï¼ˆä¾‹: 'tutorial'ï¼‰
        state: ç¾åœ¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹
        step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
        previous_actions: ã“ã‚Œã¾ã§ã®è¡Œå‹•å±¥æ­´
        gemini_model: Gemini API ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        memory_stream: ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰è¨˜æ†¶ã‚¹ãƒˆãƒªãƒ¼ãƒ 

    Returns:
        WorldModelResponse: æ¨è«–çµæœã¨é¸æŠã•ã‚ŒãŸè¡Œå‹•
    """

    # è¨˜æ†¶ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’å–å¾—
    reflection = None
    recent_episodes = []
    if memory_stream:
        reflection = memory_stream.get_reflection(level_key)
        recent_episodes = memory_stream.get_recent_episodes(level_key, limit=3)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ
    system_prompt = WorldModelPrompt.SYSTEM_PROMPT
    observation_prompt = WorldModelPrompt.create_observation_prompt(
        level, state, step, previous_actions, reflection, recent_episodes
    )

    # Gemini APIã«å•ã„åˆã‚ã›
    full_prompt = f"{system_prompt}\n\n{observation_prompt}"

    response = await gemini_model.generate_content_async(full_prompt)

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
    response_text = response.text

    # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æŠ½å‡ºï¼ˆ```json ... ``` å½¢å¼ã«å¯¾å¿œï¼‰
    json_text = response_text
    if "```json" in response_text:
        json_start = response_text.find("```json") + 7
        json_end = response_text.find("```", json_start)
        json_text = response_text[json_start:json_end].strip()
    elif "```" in response_text:
        json_start = response_text.find("```") + 3
        json_end = response_text.find("```", json_start)
        json_text = response_text[json_start:json_end].strip()

    try:
        parsed = json.loads(json_text)
        reasoning = parsed.get("reasoning", "")
        action_dict = parsed.get("action", {})

        # Actionãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        action = Action(**action_dict)

        return WorldModelResponse(
            reasoning=reasoning,
            action=action,
            raw_response=response_text,
        )

    except (json.JSONDecodeError, Exception) as e:
        # ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯å®‰å…¨ãªå¾…æ©Ÿã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿”ã™
        print(f"âš ï¸  Failed to parse Gemini response: {e}")
        print(f"Raw response: {response_text}")

        return WorldModelResponse(
            reasoning="å¿œç­”ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸãŸã‚ã€è¦³å¯Ÿã‚’å®Ÿè¡Œã—ã¾ã™",
            action=Action(
                type="observe",
                focus="state",
                reason="å¿œç­”è§£æã‚¨ãƒ©ãƒ¼",
            ),
            raw_response=response_text,
        )


def create_episode_summary(
    level_name: str,
    success: bool,
    steps: int,
    reward: float,
    actions_taken: list[str],
) -> str:
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆï¼ˆè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ ç”¨ï¼‰"""

    result = "æˆåŠŸ" if success else "å¤±æ•—"

    summary = f"""å€‰åº«ç•ªã‚¿ã‚¹ã‚¯å®Œäº† - {level_name}
çµæœ: {result}
ã‚¹ãƒ†ãƒƒãƒ—æ•°: {steps}
ç²å¾—å ±é…¬: {reward:.1f}
å®Ÿè¡Œã—ãŸè¡Œå‹•: {", ".join(actions_taken[:10])}{"..." if len(actions_taken) > 10 else ""}

"""

    if success:
        if steps < 10:
            summary += "éå¸¸ã«åŠ¹ç‡çš„ãªè§£æ³•ã‚’ç™ºè¦‹ã—ã¾ã—ãŸã€‚"
        elif steps < 20:
            summary += "é©åº¦ãªã‚¹ãƒ†ãƒƒãƒ—æ•°ã§ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚"
        else:
            summary += "æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã—ãŸãŒã€ã‚´ãƒ¼ãƒ«ã«åˆ°é”ã—ã¾ã—ãŸã€‚"
    else:
        summary += "å¤±æ•—ã‹ã‚‰å­¦ã³ã€æ¬¡å›ã¯æ”¹å–„ãŒå¿…è¦ã§ã™ã€‚"

    return summary
